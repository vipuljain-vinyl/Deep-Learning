{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: lam = 0.0001 seed = 1\n",
      "Running: lam = 0.0001 seed = 2\n",
      "Running: lam = 0.0001 seed = 3\n",
      "Running: lam = 0.0001 seed = 4\n",
      "Running: lam = 0.0001 seed = 5\n",
      "Running: lam = 0.001 seed = 1\n",
      "Running: lam = 0.001 seed = 2\n",
      "Running: lam = 0.001 seed = 3\n",
      "Running: lam = 0.001 seed = 4\n",
      "Running: lam = 0.001 seed = 5\n",
      "Running: lam = 0.01 seed = 1\n",
      "Running: lam = 0.01 seed = 2\n",
      "Running: lam = 0.01 seed = 3\n",
      "Running: lam = 0.01 seed = 4\n",
      "Running: lam = 0.01 seed = 5\n",
      "Running: lam = 0.1 seed = 1\n",
      "Running: lam = 0.1 seed = 2\n",
      "Running: lam = 0.1 seed = 3\n",
      "Running: lam = 0.1 seed = 4\n",
      "Running: lam = 0.1 seed = 5\n",
      "Running: lam = 1 seed = 1\n",
      "Running: lam = 1 seed = 2\n",
      "Running: lam = 1 seed = 3\n",
      "Running: lam = 1 seed = 4\n",
      "Running: lam = 1 seed = 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def theta(x1, x2):\n",
    "    # Calculate theta as provided in the question\n",
    "    return torch.atan(x2/x1)\n",
    "\n",
    "def r(x1, x2):\n",
    "    # Calculate r as provided in the question\n",
    "    return torch.sqrt(torch.square(x1) + torch.square(x2))    \n",
    "\n",
    "def y(x1, x2):\n",
    "    # First calculate r and theta using the functions defined above and\n",
    "    # then calculate y as provided in the question.\n",
    "    theta_value = theta(x1,x2)\n",
    "    r_value = r(x1,x2)\n",
    "    y_value = torch.square(r_value)*(torch.square(torch.sin(6*theta_value + 2*r_value) + 1))\n",
    "    return y_value\n",
    "\n",
    "def grad_theta_x1(x1, x2):\n",
    "    # Calculate the gradient of theta w.r.t. x1\n",
    "    x1_ = x1#.clone().detach().requires_grad_(True)\n",
    "    theta_value = theta(x1_, x2)\n",
    "    grad, = torch.autograd.grad(theta_value, x1_, retain_graph=True)\n",
    "    return grad\n",
    "    \n",
    "\n",
    "def grad_theta_x2(x1, x2):\n",
    "    # Calculate the gradient of theta w.r.t. x2\n",
    "    x2_ = x2#.clone().detach().requires_grad_(True)\n",
    "    theta_value = theta(x1, x2_)\n",
    "    grad, = torch.autograd.grad(theta_value, x2_, retain_graph=True)\n",
    "    return grad\n",
    "\n",
    "def grad_r_x1(x1, x2):\n",
    "    # Calculate the gradient of r w.r.t. x1\n",
    "    x1_ = x1#.clone().detach().requires_grad_(True)\n",
    "    r_val = r(x1_, x2)\n",
    "    grad, = torch.autograd.grad(r_val, x1_, retain_graph=True)\n",
    "    return grad\n",
    "    \n",
    "\n",
    "def grad_r_x2(x1, x2):\n",
    "    # Calculate the gradient of r w.r.t. x2\n",
    "    x2_ = x2#.clone().detach().requires_grad_(True)\n",
    "    r_val = r(x1, x2_)\n",
    "    grad, = torch.autograd.grad(r_val, x2_, retain_graph=True)\n",
    "    return grad\n",
    "\n",
    "def grad_y_theta(rval, thetaval):\n",
    "    # Calculate the gradient of y w.r.t. theta\n",
    "    theta_val = thetaval.clone().detach().requires_grad_(True)\n",
    "    r_val = rval.clone().detach()\n",
    "    inside = 6 * theta_val + 2 * r_val\n",
    "    y_val = torch.square(r_val) * torch.square(torch.sin(inside) + 1)\n",
    "    grad, = torch.autograd.grad(y_val, theta_val, retain_graph=True)\n",
    "    return grad\n",
    "\n",
    "def grad_y_r(rval, thetaval):\n",
    "    # Calculate the gradient of y w.r.t. r\n",
    "    r_val = rval.clone().detach().requires_grad_(True)\n",
    "    theta_val = thetaval.clone().detach()\n",
    "    inside = 6 * theta_val + 2 * r_val\n",
    "    y_val = torch.square(r_val) * torch.square(torch.sin(inside) + 1)\n",
    "    grad, = torch.autograd.grad(y_val, r_val, retain_graph=True)\n",
    "    return grad\n",
    "\n",
    "def grad_y_x1(x1, x2):\n",
    "    # Calculate the gradient of y w.r.t. x1. First\n",
    "    # calculate the gradients of y w.r.t. theta and r using the\n",
    "    # functions defined above. Then calculate the gradients of theta and\n",
    "    # r w.r.t. x1 using the functions defined above. Finally, use the\n",
    "    # chain rule to calculate the gradient of y w.r.t. x1.\n",
    "    x1 = x1.clone().detach().requires_grad_(True)\n",
    "    x2 = x2.clone().detach().requires_grad_(True)\n",
    "\n",
    "    thetaval = theta(x1, x2)\n",
    "    rval = r(x1, x2)\n",
    "    return grad_y_theta(rval, thetaval) * grad_theta_x1(x1, x2) + grad_y_r(rval, thetaval) * grad_r_x1(x1, x2)\n",
    "\n",
    "def grad_y_x2(x1, x2):\n",
    "    # Calculate the gradient of y w.r.t. x2. First\n",
    "    # calculate the gradients of y w.r.t. theta and r using the\n",
    "    # functions defined above. Then calculate the gradients of theta and\n",
    "    # r w.r.t. x2 using the functions defined above. Finally, use the\n",
    "    # chain rule to calculate the gradient of y w.r.t. x2.\n",
    "    x1 = x1.clone().detach().requires_grad_(True)\n",
    "    x2 = x2.clone().detach().requires_grad_(True)\n",
    "\n",
    "    thetaval = theta(x1, x2)\n",
    "    rval = r(x1, x2)\n",
    "\n",
    "    return grad_y_theta(rval, thetaval) * grad_theta_x2(x1, x2) + grad_y_r(rval, thetaval) * grad_r_x2(x1, x2)\n",
    "\n",
    "\n",
    "\n",
    "seeds = [1, 2, 3, 4, 5] # seeds\n",
    "num_steps = 2000 # maximum number of steps\n",
    "tol = 1e-3 # error tolerance\n",
    "lams_list = [1e-4, 1e-3, 1e-2, 1e-1, 1] # step size list\n",
    "\n",
    "# For plotting\n",
    "x1 = torch.linspace(-5, 5, 100)\n",
    "x2 = torch.linspace(-5, 5, 100)\n",
    "X1, X2 = torch.meshgrid(x1, x2, indexing=\"ij\")\n",
    "\n",
    "Y = y(X1, X2)\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "for lam_idx, lam in enumerate(lams_list):\n",
    "    for seed in seeds:\n",
    "        print(\"Running: lam =\", lam, \"seed =\", seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        # Find random starting points for x1 and x2 between [-5, 5] x\n",
    "        # [-5, 5] using torch.rand\n",
    "        x1 = (torch.rand(1) * 10.0) - 5.0\n",
    "        x2 = (torch.rand(1) * 10.0) - 5.0\n",
    "\n",
    "        # Store the values for plotting\n",
    "        y_vals = []\n",
    "        x1_vals = [x1.item()]\n",
    "        x2_vals = [x2.item()]\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # Detach x1 and x2 to reset gradient history\n",
    "            x1 = x1.detach()\n",
    "            x2 = x2.detach()\n",
    "\n",
    "            # Calculate the value of y\n",
    "            yval = y(x1, x2).item()\n",
    "\n",
    "            # Store the value\n",
    "            y_vals.append(yval)\n",
    "\n",
    "            # Calculate the gradients\n",
    "            x1_grad = grad_y_x1(x1, x2)\n",
    "            x2_grad = grad_y_x2(x1, x2)\n",
    "\n",
    "            # Write the update equation for x1 and x2\n",
    "            x1 = x1 - lam * x1_grad\n",
    "            x2 = x2 - lam * x2_grad\n",
    "\n",
    "            # Store the updated values for plotting\n",
    "            x1_vals.append(x1.item())\n",
    "            x2_vals.append(x2.item())\n",
    "\n",
    "            # If the error is less than tol, break\n",
    "            if yval < tol:\n",
    "                break\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "        im = axs[0].contourf(X1, X2, Y, cmap=\"Spectral\", levels=100)\n",
    "        axs[0].plot(x1_vals, x2_vals, linewidth=2, marker=\".\", color=\"black\", markersize=2)\n",
    "        axs[0].set_xlabel(\"X1\")\n",
    "        axs[0].set_ylabel(\"X2\")\n",
    "        fig.colorbar(im, ax=axs[0])\n",
    "\n",
    "        axs[1].plot(torch.arange(len(y_vals)), y_vals)\n",
    "        axs[1].set_yscale(\"log\")\n",
    "        axs[1].set_xlabel(\"step\")\n",
    "        axs[1].grid(True)\n",
    "        axs[1].set_ylabel(\"y\")\n",
    "\n",
    "        fig.suptitle(f\"Step size: {lam}, seed: {seed}\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(f\"plots/q1_{lam}_{seed}.png\", dpi=300)\n",
    "        plt.clf()\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vipul\\anaconda3\\Lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(\"Project1_data.pt\", map_location=\"cpu\",\n",
    "                  weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_train': tensor([[ 1.4707, -0.7200],\n",
       "         [ 1.3256, -0.9847],\n",
       "         [-0.2225, -1.3558],\n",
       "         ...,\n",
       "         [ 0.0986, -1.2125],\n",
       "         [-0.8380, -1.6739],\n",
       "         [ 1.8957,  0.0257]]),\n",
       " 'y_train': tensor([ 0.7964,  0.8817, -0.3249,  ..., -0.2669, -0.2107,  1.0144]),\n",
       " 'x_val': tensor([[-0.8223, -0.3132],\n",
       "         [ 0.0620, -1.4935],\n",
       "         [ 0.1083,  1.6470],\n",
       "         ...,\n",
       "         [-1.1555,  0.6633],\n",
       "         [-0.4865, -0.8899],\n",
       "         [-0.8752,  1.2963]]),\n",
       " 'y_val': tensor([-1.1388, -0.0296,  0.0318,  ..., -0.6416, -1.0597, -0.5482]),\n",
       " 'x_test': tensor([[ 0.9259, -0.2573],\n",
       "         [ 0.6018,  0.2774],\n",
       "         [ 0.5279, -0.4669],\n",
       "         ...,\n",
       "         [-0.4902, -0.2149],\n",
       "         [ 0.2128,  1.5805],\n",
       "         [ 1.6260, -0.4681]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(data[\"x_train\"], data[\"y_train\"].reshape(-1, 1))\n",
    "val_dataset = TensorDataset(data[\"x_val\"], data[\"y_val\"].reshape(-1, 1))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "step = 0\n",
    "train_step_count = []\n",
    "val_step_count = []\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "# for i in trange(num_epochs):\n",
    "#     mlp.train()\n",
    "#     mse.train()\n",
    "for batch in tqdm(train_dataloader, desc=\"Training\", leave=False):\n",
    "    X, y = batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
